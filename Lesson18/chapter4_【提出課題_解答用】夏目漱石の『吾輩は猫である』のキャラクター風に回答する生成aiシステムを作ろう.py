# -*- coding: utf-8 -*-
"""Chapter4:【提出課題: 解答用】夏目漱石の『吾輩は猫である』のキャラクター風に回答する生成AIシステムを作ろう

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W2w1ACGq0emB80WGkK1iD9CnqPuXmtN-

# Lesson18: ファインチューニング
# Chapter4:【提出課題: 解答用】夏目漱石の『吾輩は猫である』のキャラクター風に回答する生成AIシステムを作ろう

事前準備を行った上で、提出課題に取り組みましょう。

**【提出方法】**  
Slackでメンターをメンションの上、当シート右上の「共有」からリンクをコピーし、提出してください。

## 事前準備

OpenAI APIキーの設定
"""

import os
from google.colab import userdata

os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY")

"""ライブラリのインストール"""

!pip install openai==1.47.0 httpx==0.27.2

"""## 提出課題

### 【問題文】

夏目漱石の『吾輩は猫である』のキャラクター（猫）の口調・性格で質問に回答する生成AIシステムを、  
条件に従いファインチューニングを使って作りましょう。


**【『吾輩は猫である』の小説テキスト】**  
https://www.aozora.gr.jp/cards/000148/files/789_14547.html


**【入力例】**  
最近ストレスが多いです。


**【回答例】**  
吾輩が思うに、ストレスとは心の毛玉である。時折、のんびりとしたひとときを過ごすことでほぐれるであろう。


**【条件】**
*   学習用のデータセット50件を格納したCSVファイルを作ってください。
*   プロンプトのシステムメッセージはご自身で考えてください。
*   ファインチューニングを行うモデルは、ご自身で自由に選んでください。
*   学習用データは、ChatGPTやClaudeなどの生成AIツールを使って生成してください。

### 【解答】
"""

import pandas as pd
import json
from openai import OpenAI
import time
import openai

# ----------------------------------------------
# 1. 学習用データの準備
# ----------------------------------------------
input_data = "/content/neko_training_50.csv"
#input_data = r"C:\work\ws_python\GenerationAiCamp\Lesson18\学習用データセット.csv"
# ----------------------------------------------
# 2. JSONL形式への変換
# ----------------------------------------------
jsonl_file_name = "学習用データセット.jsonl"

# CSVファイルの読み込み
df = pd.read_csv(input_data)

# CSVファイルの各行のデータを、Chat Completions APIに対応した辞書形式に変換する
jsonl_data = []
system_message = {
    "role": "system",
    "content": "夏目漱石の『吾輩は猫である』のキャラクター（猫）の口調・性格で質問に対して回答するアシスタントAIです。"
    #"content": "あなたは織田信長の口調・性格で、質問に対して名言を織り交ぜて回答するアシスタントAIです。"
}

for _, row in df.iterrows():
    record = {
        "messages": [
            system_message,
            {"role": "user", "content": row[0]},
            {"role": "assistant", "content": row[1]}
        ]
    }

    jsonl_data.append(record)

# JSONL形式のファイルにCSVファイルの各行のデータを書き込む
# ※最終行のみ、改行を付けない
with open(jsonl_file_name, 'w', encoding='utf-8') as jsonl_file:

    data_len = len(jsonl_data)
    for i, entry in enumerate(jsonl_data):
        if data_len - 1 == i:
            jsonl_file.write(json.dumps(entry, ensure_ascii=False))
        else:
            jsonl_file.write(json.dumps(entry, ensure_ascii=False) + '\n')

# ----------------------------------------------
# 3. 事前学習済みモデルの用意
# ----------------------------------------------
# 学習させるモデル（事前学習済みモデル）のインスタンスを用意します。
# 事前学習済みモデルにはChatOpenAIではなく、OpenAIを使いましょう。
client = OpenAI()

# ジョブステータス監視処理
def wait_until_succeeded(job_id, interval=300, timeout=1800):
    """ジョブが succeeded になるまで待機し、後続処理を実行"""
    start_time = time.time()
    while True:
        job = client.fine_tuning.jobs.retrieve(job_id)
        status = job.status
        print(f"[{time.strftime('%H:%M:%S')}] 現在のステータス: {status}")

        if status == "succeeded":
            print("✅ ジョブが succeeded 状態になりました。後続処理を開始します。")
            run_followup(job)
            break
        elif status in ["failed", "cancelled"]:
            print(f"❌ ジョブが失敗またはキャンセルされました。status: {status}")
            break
        elif time.time() - start_time > timeout:
            print("⏰ タイムアウトしました。ジョブが succeeded になりませんでした。")
            break

        time.sleep(interval)

def run_followup(job):
    """後続処理（例：ログ出力や通知など）"""
    print(f"📝 モデルID: {job.fine_tuned_model}")
    # ここに推論処理や通知処理などを記述
    # 例: 推論テスト、Slack通知、DB登録など

# ----------------------------------------------
# 4. 学習データのモデルへのアップロード
# ----------------------------------------------
# 準備した学習データを、モデルにアップロードします。
# ここでいうアップロードとは、ファインチューニングを行う前準備のようなものだと思ってください。
# 以下のコードを実行することで、学習データをモデルにアップロードできます。

# モデルオブジェクトの「files.create()」メソッドの引数に、学習させるファイルと、
# ファインチューニングを行うことを示す「fine-tune」の値を渡します。
# 戻り値として学習用ファイルのオブジェクトが返ってきます。
# 変数「file_obj」の「id」属性に学習用ファイルのIDが格納されているため、
# この値を後ほどファインチューニングの実行の際に使います。
# これで、ファインチューニングを行う準備は完了です。
file_obj = client.files.create(
    file=open(jsonl_file_name, "rb"),
    purpose="fine-tune"
)

# ----------------------------------------------
# 5. ファインチューニングの実行
# ----------------------------------------------
# 「training_file」引数には、
# 先ほどモデルにファイルをアップロードした際に戻り値として返ってきた、ファイルオブジェクトのIDを指定します。
# またOpenAIの公式サイトに「gpt-4o-mini」がほとんどのユーザーにとっておすすめであることが記載されているため、
# ここではモデルに「gpt-4o-mini」を使っています。
# 環境によっては「gpt-4o-mini」だと正常に動作しないことがあるため、その場合は「gpt-3.5-turbo」を使ってください。
job = client.fine_tuning.jobs.create(
    training_file=file_obj.id,
    #model="gpt-4o-mini-2024-07-18"
    model="gpt-3.5-turbo"

)

# ステータス監視の実行
wait_until_succeeded(job.id)

# ----------------------------------------------
# 6. 学習ステータスの確認
# ----------------------------------------------
# 実行結果の中で見るべきは、「fine_tuned_model」と「status」の属性値です。
fine_tuned_job = client.fine_tuning.jobs.retrieve(job.id)
print(fine_tuned_job)

# 【出力結果の見方】
# ファインチューニングの実行後、まず「status」が「validating_files」になります。
# しばらく経つと「running」になります。

# ファインチューニングに成功すると「succeeded」に、失敗すると「failed」になります。
# statusの値が「succeeded」か「failed」のどちらかになるまでに3〜5分程度、場合によってはこれ以上かかる可能性があります。
# 時間を空けて何度か実行しながら待ちましょう。

# ファインチューニングの実行に失敗した場合、学習データに何らかの不備が存在する可能性が高いです。
# また大量のデータを学習させる場合は、エラーが発生しやすくなります。
# エラーメッセージが表示されるため、確認して修正しましょう。

# statusの値が「succeeded」になると、以下のように「fine_tuned_model」に
# ファインチューニング後の個別のモデル名が格納されます。
# ファインチューニング済みのモデルを利用する際は、この個別のモデル名を指定する必要があります。

# ----------------------------------------------
# 7. ファインチューニング済みモデルの利用
# ----------------------------------------------
# statusの値が「succeeded」になりファインチューニングの実行に成功したら、ファインチューニング済みのモデルを利用してみましょう。
# 以下は、「成功の秘訣は？」という質問に対してLLMからの回答を得るコードです。

# 引数「model」には、先ほど学習ステータスの確認の際に取得した、個別のモデル名である「fine_tuned_model」の値を渡します。
# また引数「messages」には、システムメッセージとユーザー入力値を渡します。
completion = client.chat.completions.create(
    model=fine_tuned_job.fine_tuned_model,
    messages=[
        {"role": "system", "content": "夏目漱石の『吾輩は猫である』のキャラクター（猫）の口調・性格で質問に対して回答するアシスタントAIです。"},
        {"role": "user", "content": "あなたは、どんな猫ですか？"}
        # {"role": "system", "content": "あなたは織田信長の口調・性格で、質問に対して名言を織り交ぜて回答するアシスタントAIです。"},
        # {"role": "user", "content": "成功の秘訣は？"}
    ]
)

# ファインチューニング済みモデルによる実行結果が変数「completion」に格納されるため、
# オブジェクトの中の属性をたどってLLMによる回答を出力しています。
# ここまで7つの手順で解説してきた通り、ファインチューニングを実行する方法は極めてシンプルです。
# 学習用データを準備し、ファインチューニングを実行するだけです。
# 重要なのは、「どんな学習用データを準備するか」です。
# 学習用データの品質が悪いと、ファインチューニング済みモデルによる回答の精度が低くなります。
# ファインチューニングができたら、質問に対して期待する回答が返ってくるかを確認し、返ってこない場合は
# 学習用データの品質を改善したり、データ量を増やしたり、またプロンプトを調整したりして、
# 何度も試行錯誤しながらチューニング（調整）を行います。
# プロンプトエンジニアリングの工夫をどれだけ行っても生成AIシステムの目的を達成できない場合、
# ファインチューニングを行って回答精度の向上にトライしてみてください。
print(completion.choices[0].message.content)





































