# -*- coding: utf-8 -*-
"""【教材ソースコード】Lesson14: Agents

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O759pa0qQUR1Kte0_lYd_XscoEHeYsMZ

# 【教材ソースコード】Lesson14: LangChainの主要モジュール5【Agents（AIエージェント）】

## 事前準備
シークレット機能でOpenAI APIのAPIキーを設定し、以下2つのコードを実行しましょう。
"""

import os
from google.colab import userdata

os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY")

!pip install langchain==0.3.0 openai==1.47.0 langchain-community==0.3.0 httpx==0.27.2 pydantic==2.9.2

"""## 教材サンプルコード

### Chapter4: Agents実装の導入

---
"""

!pip install duckduckgo-search==8.1.1

from langchain.agents import AgentType, initialize_agent, load_tools
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

tools = load_tools(["ddg-search"])

agent_executor = initialize_agent(
    llm=llm,
    tools=tools,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent_executor.run("2024年12月現在の日本の総理大臣は誰ですか？")

"""### Chapter5: 標準Tool

#### wikipedia
"""

!pip install wikipedia==1.4.0

from langchain.agents import AgentType, initialize_agent, load_tools
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

tools = load_tools(["wikipedia"])

agent_executor = initialize_agent(
    llm=llm,
    tools=tools,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent_executor.run("江戸時代の食文化について教えて")

"""#### llm-math"""

from langchain.agents import AgentType, initialize_agent, load_tools
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

tools = load_tools(["llm-math"], llm=llm)

agent_executor = initialize_agent(
    llm=llm,
    tools=tools,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent_executor.run("320の15%は何ですか？")

from langchain.agents import AgentType, initialize_agent, load_tools
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

tools = load_tools(["llm-math"], llm=llm)

agent_executor = initialize_agent(
    llm=llm,
    tools=tools,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

query = """
ある都市の人口は現在100万人です。毎年2%ずつ人口が増えると仮定しますが、
5年後に新たな法律が施行され、その影響で毎年3%ずつ人口が減ると予想されています。
この都市の人口が10年後にどれだけ変化しているか計算してください。
"""

agent_executor.run(query)

"""#### serpapi"""

!pip install google-search-results==2.4.2

os.environ["SERPAPI_API_KEY"] = userdata.get("SERPAPI_API_KEY")

from langchain.agents import AgentType, initialize_agent, load_tools
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

tools = load_tools(["serpapi"])

agent_executor = initialize_agent(
    llm=llm,
    tools=tools,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent_executor.run("富士山の高さは？")

"""### Chapter6: 自作Tool

#### 簡単な処理のTool化
"""

from langchain.tools import Tool

def select_snack(param):
    return "どちらも最高なので、決められません！"

answer_tool = Tool.from_function(
    func=select_snack,
    name="お菓子の好みについての回答例",
    description="「きのこ」と「たけのこ」のどっち派かを聞かれた際の回答例"
)

from langchain.agents import AgentType, initialize_agent, load_tools
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

tools = [answer_tool]

agent_executor = initialize_agent(
    llm=llm,
    tools=tools,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent_executor.run("友達に「きのこ」と「たけのこ」のどっち派かを聞かれたら、どう答えれば良い？")

"""nameとdescriptionの質が低いとどうなるか"""

from langchain.tools import Tool

def select_snack(param):
    return "どちらも最高なので、決められません！"

answer_tool = Tool.from_function(
    func=select_snack,
    name="計算機",
    description="計算をする"
)

from langchain.agents import AgentType, initialize_agent, load_tools
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

tools = [answer_tool]

agent_executor = initialize_agent(
    llm=llm,
    tools=tools,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent_executor.run("友達に「きのこ」と「たけのこ」のどっち派かを聞かれたら、どう答えれば良い？")

"""#### ChainsのTool化"""

from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain import LLMChain

system_template = """
以下の3つを、それぞれ50文字程度の簡単な紹介付きで答えてください。

おすすめの観光スポット:
1. 兼六園
2. 金沢21世紀美術館
3. 近江町市場

出力:
"""

prompt = ChatPromptTemplate.from_messages([
    ("system", system_template),
    ("human", "{input}")
])

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

chain = LLMChain(prompt=prompt, llm=llm)

from langchain.tools import Tool

answer_tool = Tool.from_function(
    func=chain.run,
    name="石川県のおすすめの観光スポット",
    description="石川県のおすすめの観光スポットについて聞かれたら答える"
)

from langchain.agents import AgentType, initialize_agent

tools = [answer_tool]

agent_executor = initialize_agent(
    llm=llm,
    tools=tools,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent_executor.run("石川県のおすすめの観光スポットはどこですか？")

"""### Chapter7: 複数のTool利用

#### 標準Tool
"""

from langchain.agents import AgentType, initialize_agent, load_tools
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

tools = load_tools(["wikipedia", "llm-math", "serpapi"], llm=llm)

agent_executor = initialize_agent(
    llm=llm,
    tools=tools,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent_executor.run("320の15%は何ですか？")

agent_executor.run("2024年12月現在の日本の総理大臣は誰ですか？")

agent_executor.run("オリンピックの歴史を教えて")

"""#### 自作Tool"""

from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain import LLMChain

def result_chain(param, system_template):
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_template),
        ("human", "{input}")
    ])

    chain = LLMChain(prompt=prompt, llm=llm)

    result = chain.run(param)
    return result

from langchain.tools import Tool

def get_childcare_stress_advice(param):
    system_template = """
    あなたは親の育児ストレスを軽減するための専門家です。
    育児疲れやストレス管理に関する実践的なアドバイスを提供します。
    親自身の心身の健康を保つための方法を教えます。
    """

    result = result_chain(param, system_template)
    return result

childcare_stress_advice_tool = Tool.from_function(
    func=get_childcare_stress_advice,
    name="親の育児ストレス軽減に詳しい専門家",
    description="親の育児疲れやストレス管理に関する実践的なアドバイスを提供する"
)

def get_childcare_nutrition_advice(param):
    system_template = """
    あなたは子どもの栄養に詳しいアドバイザーです。
    子どもの健康な発育を支える食事や栄養バランスについてアドバイスを提供します。
    食事の習慣や偏食に関する質問にも丁寧に答えます。
    """

    result = result_chain(param, system_template)
    return result

childcare_nutrition_advice_tool = Tool.from_function(
    func=get_childcare_nutrition_advice,
    name="子どもの栄養に詳しい専門家",
    description="子どもの健康な発育を支える食事や栄養バランスについてアドバイスを提供する"
)

def get_childcare_sleep_advice(param):
    system_template = """
    あなたは子どもの睡眠習慣に詳しい専門家です。
    子どもの夜泣きや睡眠不足に関する解決策を提供し、健全な睡眠を促すためのアドバイスを行います。
    親が子どもの睡眠問題に対処できるようサポートします。
    """

    result = result_chain(param, system_template)
    return result

childcare_sleep_advice_tool = Tool.from_function(
    func=get_childcare_sleep_advice,
    name="子どもの睡眠習慣に詳しい専門家",
    description="子どもの夜泣きや睡眠不足に関する解決策を提供し、健全な睡眠を促すためのアドバイスを行う"
)

def get_childcare_balance_advice(param):
    system_template = """
    あなたは働く親のための育児と仕事の両立に詳しいアドバイザーです。
    仕事と育児のバランスを保つための実践的なアドバイスを提供し、時間管理や家族とのコミュニケーションをサポートします。
    """

    result = result_chain(param, system_template)
    return result

childcare_balance_advice_tool = Tool.from_function(
    func=get_childcare_balance_advice,
    name="働く親のための育児と仕事の両立に詳しい専門家",
    description="仕事と育児のバランスを保つための実践的なアドバイスを提供する"
)

from langchain.agents import AgentType, initialize_agent, load_tools

tools = [
    childcare_stress_advice_tool,
    childcare_nutrition_advice_tool,
    childcare_sleep_advice_tool,
    childcare_balance_advice_tool
]

agent_executor = initialize_agent(
    llm=llm,
    tools=tools,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent_executor.run("子どものイヤイヤ期で疲れています。ストレスを軽減する方法を教えてください。")

agent_executor.run("2歳の子どもに適したおやつの選び方を教えてください。")

agent_executor.run("昼寝の時間をどのように調整すれば夜の睡眠を妨げませんか？")

agent_executor.run("忙しい平日に効率よく育児と仕事を両立する方法を教えてください。")

"""#### 標準Tool + 自作Tool"""

from langchain.agents import AgentType, initialize_agent, load_tools
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

tools = load_tools(["llm-math"], llm=llm)

agent_executor = initialize_agent(
    llm=llm,
    tools=tools,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent_executor.run("健康に良い習慣を教えて")

"""一般的な入力に対して回答するAgents"""

from langchain.tools import Tool
from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain import LLMChain

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

system_template = "敬語を使わず、友達と喋るノリでリラックスしたトーンでユーザーと会話してください。"
prompt = ChatPromptTemplate.from_messages([
    ("system", system_template),
    ("human", "{input}")
])

chain = LLMChain(prompt=prompt, llm=llm)

general_answer_tool = Tool.from_function(
    func=chain.run,
    name="数学問題以外の一般的な入力に対しての回答",
    description="数学問題以外の一般的な入力に対して回答を行う"
)

from langchain.agents import AgentType, initialize_agent, load_tools

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

tools = load_tools(["llm-math"], llm=llm)
tools.append(general_answer_tool)

agent_executor = initialize_agent(
    llm=llm,
    tools=tools,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent_executor.run("健康に良い習慣を教えて")

"""### Chapter8: 「Agents」×「Retrieval」のシステム開発"""

!pip install pymupdf==1.24.11 tiktoken==0.8.0 chromadb==0.5.11

from langchain_community.document_loaders import PyMuPDFLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.schema import HumanMessage, AIMessage
from langchain import LLMChain
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

def create_rag_chain(file):
    loader = PyMuPDFLoader(file)
    pages = loader.load()
    text_splitter = CharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=30,
        separator="\n",
    )
    splitted_pages = text_splitter.split_documents(pages)
    embeddings = OpenAIEmbeddings()
    db = Chroma.from_documents(splitted_pages, embedding=embeddings)
    retriever = db.as_retriever()

    question_generator_template = "会話履歴と最新の入力をもとに、会話履歴なしでも理解できる独立した入力テキストを生成してください。"
    question_generator_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", question_generator_template),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )

    question_answer_template = """
    あなたは優秀な質問応答アシスタントです。以下のcontextを使用して質問に答えてください。
    また答えが分からない場合は、無理に答えようとせず「分からない」という旨を答えてください。"

    {context}
    """

    question_answer_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", question_answer_template),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )

    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)
    history_aware_retriever = create_history_aware_retriever(
        llm, retriever, question_generator_prompt
    )

    question_answer_chain = create_stuff_documents_chain(llm, question_answer_prompt)
    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)

    return rag_chain

service_doc_chain = create_rag_chain("healthX_instructions.pdf")
customer_doc_chain = create_rag_chain("customer_interactions_history.pdf")

global service_doc_chain_chat_history
global customer_doc_chain_chat_history

service_doc_chain_chat_history = []
customer_doc_chain_chat_history = []

def run_service_doc_chain(param):
    ai_msg = service_doc_chain.invoke({"input": param, "chat_history": service_doc_chain_chat_history})
    service_doc_chain_chat_history.extend([HumanMessage(content=param), AIMessage(content=ai_msg["answer"])])
    return ai_msg["answer"]

from langchain.tools import Tool

service_doc_tool = Tool.from_function(
    func=run_service_doc_chain,
    name="自社サービス「HealthX」に関する情報を参照するTool",
    description="自社サービス「HealthX」に関する情報を参照したい場合に使う"
)

def run_customer_doc_chain(param):
    ai_msg = customer_doc_chain.invoke({"input": param, "chat_history": customer_doc_chain_chat_history})
    customer_doc_chain_chat_history.extend([HumanMessage(content=param), AIMessage(content=ai_msg["answer"])])
    return ai_msg["answer"]

customer_doc_tool = Tool.from_function(
    func=run_customer_doc_chain,
    name="自社顧客との過去のやり取りを参照するTool",
    description="自社顧客と過去、どのようなやり取りが行われたかを確認したい時に使う"
)

from langchain.agents import AgentType, initialize_agent, load_tools
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

tools = [service_doc_tool, customer_doc_tool]

agent_executor = initialize_agent(
    llm=llm,
    tools=tools,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent_executor.run("HealthXの特徴を教えてください")

agent_executor.run("「アクアテック株式会社」との、導入後のサポート依頼についてのやり取りはいつ行われましたか？")

"""### Chapter9: 外部サービスの自動操作"""

os.environ["SLACK_USER_TOKEN"] = userdata.get("SLACK_USER_TOKEN")

!pip install langchain==0.3.20 langchain-community==0.3.19 slack_sdk==3.34.0

from langchain_community.agent_toolkits import SlackToolkit

toolkit = SlackToolkit()

tools = toolkit.get_tools()

tools

from langchain.chat_models import ChatOpenAI
from langchain.agents import AgentType, initialize_agent

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.5)

agent_executor = initialize_agent(
    llm=llm,
    tools=tools,
    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent_executor.invoke({"input": "「動作検証用」チャンネルに「Hello」と送信して"})

result = agent_executor.invoke({"input": "「動作検証用」チャンネルに投稿された最新のメッセージを表示して"})

result["output"]

result = agent_executor.invoke({"input": "チャンネル名を一覧化して"})

result["output"]

member_id = "U08G8GQCYBD"

agent_executor.invoke({"input": f"「動作検証用」チャンネルで、ID「{member_id}」のメンバーにメンションを当てて「こんにちは」と送信して"})