# -*- coding: utf-8 -*-
"""【教材ソースコード】Lesson10: Output Parser

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15QRSR-NsHWkApraHeeNW_0s7VV5iyo4J

# 【教材ソースコード】Lesson10: LangChainの主要モジュール1【Model I/O】：Output Parser

## 事前準備

OpenAI APIキーの設定
"""

import os
from google.colab import userdata

os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY")

"""各種パッケージのインストール"""

!pip install langchain==0.3.0 openai==1.47.0 langchain-community==0.3.0 langchain-openai==0.2.2 httpx==0.27.2 pydantic==2.9.2

"""## 教材ソースコード

### Chapter3: 型変換のOutput Parser

---

#### Structured output parser

1. ライブラリを読み込む
"""

from langchain.output_parsers import StructuredOutputParser, ResponseSchema
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

"""2. LLMから返してほしい回答の型を定義する"""

schemas = [
    ResponseSchema(name="programming_language", description="プログラミング言語"),
    ResponseSchema(name="overview", description="プログラミング言語の説明")
]

"""3. Output Parserを用意する"""

output_parser = StructuredOutputParser.from_response_schemas(schemas)

"""4. 定義した回答の型に則って、プロンプトに追加するフォーマット命令を作る"""

format_instruction = output_parser.get_format_instructions()
print(format_instruction)

"""5. フォーマット命令を含めたプロンプトを作る"""

prompt_template = PromptTemplate(
    template="AI開発におすすめのプログラミング言語を教えてください。\n{format_instruction}",
    input_variables=[],
    partial_variables={"format_instruction": format_instruction}
)
prompt = prompt_template.format_prompt()
print(prompt.text)

"""6. LLMにプロンプトを渡し、出力を得る"""

from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content=prompt.text),
]

output = llm(messages)
print(output.content)

"""7. 出力を構文解析し、プログラムで扱いやすいデータ形式に変換する"""

result = output_parser.parse(output.content)
print(result)

"""#### List parser

1. ライブラリを読み込む
"""

from langchain.output_parsers import CommaSeparatedListOutputParser
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

"""2. Output Parserを用意する"""

output_parser = CommaSeparatedListOutputParser()

"""3. プロンプトに追加するフォーマット命令を作る"""

format_instruction = output_parser.get_format_instructions()
print(format_instruction)

"""4. フォーマット命令を含めたプロンプトを作る"""

prompt_template = PromptTemplate(
    template="友達に渡す誕生日プレゼントの案を5つ挙げてください。\n{format_instruction}",
    input_variables=[],
    partial_variables={"format_instruction": format_instruction}
)

prompt = prompt_template.format_prompt()
print(prompt.text)

"""5. LLMにプロンプトを渡し、出力を得る"""

from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content=prompt.text),
]

output = llm(messages)
print(output.content)

"""6. 出力を構文解析し、プログラムで扱いやすいデータ形式に変換する"""

result = output_parser.parse(output.content)
result

"""#### Enum parser

1. ライブラリを読み込む
"""

from langchain.output_parsers.enum import EnumOutputParser
from enum import Enum
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

"""2. LLMから返してほしい回答の型を定義する"""

class Prefectures(Enum):
    PREFECTURES_1 = "北海道"
    PREFECTURES_2 = "京都府"
    PREFECTURES_3 = "沖縄県"

"""3. Output Parserを用意する"""

output_parser = EnumOutputParser(enum=Prefectures)

"""4. プロンプトに追加するフォーマット命令を作る"""

format_instruction = output_parser.get_format_instructions()
print(format_instruction)

"""5. フォーマット命令を含めたプロンプトを作る"""

prompt_template = PromptTemplate(
    template="観光におすすめの都道府県を1つ挙げてください。ただし、回答は都道府県名のみとしてください。\n{format_instruction}",
    input_variables=[],
    partial_variables={"format_instruction": format_instruction}
)

prompt = prompt_template.format_prompt()
print(prompt.text)

"""6. LLMにプロンプトを渡し、出力を得る"""

from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content=prompt.text),
]

output = llm(messages)
print(output.content)

"""7. 出力を構文解析し、プログラムで扱いやすいデータ形式に変換する"""

result = output_parser.parse(output.content)
print(result)

"""value属性で値を取り出す"""

print(result.value)

"""#### PydanticOutputParser

1. OutputParser用のクラスを読み込む
"""

from langchain.output_parsers import PydanticOutputParser

"""2. LLMから返してほしい回答の型を定義する"""

from pydantic import BaseModel, Field

class TravelPlan(BaseModel):
    destinations: list[str] = Field(description="List of destinations included in the itinerary")
    activities: list[str] = Field(description="Planned activities at each destination")
    duration: int = Field(description="Total duration of the trip in days")
    budget: float = Field(description="Estimated budget for the trip in local currency")

"""3. Output Parserを用意する"""

output_parser = PydanticOutputParser(pydantic_object=TravelPlan)

"""4. 定義した回答の型に則って、プロンプトに追加するフォーマット命令を作る"""

format_instruction = output_parser.get_format_instructions()
print(format_instruction)

"""5. フォーマット命令を含めたプロンプトを作る"""

from langchain.prompts import PromptTemplate

template = """
次のフォーマットで旅行プランを作成してください。

{format_instruction}

旅行のテーマ: {theme}
"""

prompt_template = PromptTemplate(
   template=template,
   input_variables=["theme"],
   partial_variables={"format_instruction": format_instruction}
)

prompt = prompt_template.format(theme="家族で楽しむリゾート旅行")
print(prompt)

"""6. LLMにプロンプトを渡し、出力を得る"""

from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content=prompt),
]

output = llm(messages)
print(output.content)

"""7. 出力を構文解析し、プログラムで扱いやすいデータ形式に変換する"""

result = output_parser.parse(output.content)
print(result)

print(result.destinations)

"""### Chapter4: 例外処理のOutput Parser

---

Enum parserについて解説した際のコードで、わざとエラーを発生させる
"""

from langchain.output_parsers.enum import EnumOutputParser
from enum import Enum
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

class Prefectures(Enum):
    PREFECTURES_1 = "北海道"
    PREFECTURES_2 = "京都府"
    PREFECTURES_3 = "沖縄県"

output_parser = EnumOutputParser(enum=Prefectures)

format_instruction = output_parser.get_format_instructions()

prompt_template = PromptTemplate(
    template="観光におすすめの都道府県を1つ挙げてください。ただし、回答は都道府県名のみとしてください。\n{format_instruction}",
    input_variables=[],
    partial_variables={"format_instruction": format_instruction}
)

prompt = prompt_template.format_prompt()

from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content=prompt.text),
]

output = llm(messages)
print(output.content)

result = output_parser.parse(output.content)
print(result)

"""Retry Parserで修正依頼を出す"""

from langchain.output_parsers import RetryWithErrorOutputParser

try:
    output.content = "京都"
    result = output_parser.parse(output.content)
    print(result)
except ValueError as e:
    print(f"型変換のOutput Parserで型変換を行った際にValue Errorの例外が発生しました。")
    print(f"例外の詳細: {e}")
    retry_parser = RetryWithErrorOutputParser.from_llm(
        parser=output_parser,
        llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)
    )
    result = retry_parser.parse_with_prompt(output.content, prompt)
    print(result)

print(result.value)