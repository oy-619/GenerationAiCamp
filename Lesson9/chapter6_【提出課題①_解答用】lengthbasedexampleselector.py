# -*- coding: utf-8 -*-
"""Chapter6:【提出課題①: 解答用】LengthBasedExampleSelector

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C9SBFAPSGkGlNnaJTdIWbPyx97pPpeEJ

# Lesson9: LangChainの主要モジュール1【Model I/O】：Prompts
# Chapter6:【提出課題①: 解答用】LengthBasedExampleSelector

事前準備を行った上で、提出課題に取り組みましょう。

**【提出方法】**  
Slackでメンターをメンションの上、当シート右上の「共有」からリンクをコピーし、提出してください。

## 事前準備

OpenAI APIキーの設定
"""

import os
from google.colab import userdata

os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY")

"""各種パッケージのインストール"""

!pip install langchain==0.3.0 openai==1.47.0 langchain-community==0.3.0 langchain-openai==0.2.2 httpx==0.27.2

"""## 提出課題

入力内容に応じて、20トークン以内の短い回答をプロンプトに埋め込むLengthBasedExampleSelectorを作成しましょう。  
用意する回答例はご自身で自由に設定してください。  

またroleがuserのメッセージに生成結果を渡し、Chat Completions APIで適切に回答が生成されるかを確認しましょう。
"""

# promptsモジュールから「FewShotPromptTemplate」クラス、「LengthBasedExampleSelector」クラス、「PromptTemplate」を読込む
from langchain.prompts import FewShotPromptTemplate
from langchain.prompts.example_selector import LengthBasedExampleSelector
from langchain.prompts.prompt import PromptTemplate

# 「examples」変数に回答例の一覧を用意
examples = [
    {"player": "大谷翔平", "team": "ロサンゼルス・ドジャース"},
    {"player": "菅野智之", "team": "ボルティモア・オリオールズ"},
    {"player": "吉田正尚", "team": "ボストン・レッドソックス"},
    {"player": "菊池雄星", "team": "ロサンゼルス・エンゼルス"},
    {"player": "前田健太", "team": "デトロイト・タイガース"},
    {"player": "千賀滉大", "team": "ニューヨーク・メッツ"},
    {"player": "鈴木誠也", "team": "シカゴ・カブス"},
    {"player": "ダルビッシュ有", "team": "サンディエゴ・パドレス"},
]

# 「examples_template」に回答例を埋め込むプロンプトテンプレートを用意
examples_template = """
MLB選手：{player}
MLBチーム：{team}
"""

# LengthBasedExampleSelectorクラスをインスタンス化
example_prompt = PromptTemplate(
    input_variables=["player", "team"],
    template=examples_template
)

# 用意した複数の回答例を「examples」パラメータに、また複数の回答例を埋め込むプロンプトテンプレートを「example_prompt」パラメータに指定。
# 「max_length」パラメータに「20」を指定。（プロンプトに埋め込む回答例の最大のトークン数を示す）
example_selector = LengthBasedExampleSelector(
    examples=examples,
    example_prompt=example_prompt,
    max_length=20,
)

# FewShotPromptTemplateをインスタンス化
# 「example_selector」パラメータにLengthBasedExampleSelectorクラスのインスタンスを渡す
fewshot_prompt = FewShotPromptTemplate(
    example_selector=example_selector,
    example_prompt=example_prompt,
    prefix="MLB選手が属するMLBチームを回答してください。",
    suffix="MLB選手：{player}\nチーム：",
    input_variables=["player"],
    example_separator="\n\n"
)

message = fewshot_prompt.format(player="松井祐樹")

print(message)

from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content=message),
]

result = llm(messages)
print(result.content)