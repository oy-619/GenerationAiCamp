# -*- coding: utf-8 -*-
"""Chapter3:【提出課題: 解答用】Callbacksを使ったロギングとストリーミング出力機能の実装

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r0w11U70l2SJXWoSwoFx2PhQkJeEinM2

# Lesson15: LangChainの主要モジュール6【Callbacks】
# Chapter3:【提出課題: 解答用】Callbacksを使ったロギングとストリーミング出力機能の実装

事前準備を行った上で、提出課題に取り組みましょう。

**【提出方法】**  
Slackでメンターをメンションの上、当シート右上の「共有」からリンクをコピーし、提出してください。

## 事前準備

### 【OpenAI APIキーの設定】

シークレット機能でOpenAI APIのAPIキーを設定し、以下2つのコードを実行しましょう。
"""

import os
from google.colab import userdata

os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY")

!pip install langchain==0.3.0 openai==1.47.0 langchain-community==0.3.0 httpx==0.27.2

"""## 提出課題

### 【問題文】

以下の条件に従い、LLMChainを活用したプログラムを作ってください。

**【条件】**
*   用意されているテンプレートを使ってください。
*   ChatPromptTemplateを使ってください。
*   LLMChainの詳細ログが出力されるようにしてください。
*   FileCallbackHandlerを使い、「output.log」のファイル名でLLMの実行結果・ログを出力してください。
*   LLMの回答が徐々に表示されるようにしてください。
*   Chainへの入力値は「けん玉」とします。
"""

system_template = "入力値として与えられた「趣味や特技」に取り組んでいる人に向けて、上達するためのおすすめの方法やアドバイスを3つ教えてください。"

"""### 【ヒント】

モデルのインスタンス生成時にストリーミング出力の設定を行い、

LLMChainのインスタンス作成時にロギングの設定を行いましょう。

### 【解答】
"""

!pip install loguru==0.7.3

from langchain.callbacks.base import BaseCallbackHandler
from typing import Dict, Any, List, Union, Sequence
from langchain.schema import BaseMessage, LLMResult, AgentAction, AgentFinish, Document

class CustomCallbackHandler(BaseCallbackHandler):

    def on_chat_model_start(self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], **kwargs: Any):
        """チャットモデルの処理開始時"""
        pass

    def on_llm_new_token(self, token: str, **kwargs: Any):
        """新規トークン生成時"""
        pass

    def on_llm_error(self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any):
        """LLMのエラー発生時"""
        pass

    def on_llm_end(self, response: LLMResult, **kwargs: Any):
        """LLMの処理終了時"""
        pass

    def on_chain_start(self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs: Any):
        """Chainsの処理開始時"""
        pass

    def on_chain_error(self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any):
        """Chainsのエラー発生時"""
        pass

    def on_chain_end(self, outputs: Dict[str, Any], **kwargs: Any):
        """Chainsの処理終了時"""
        pass

    def on_retriever_start(self, serialized: Dict[str, Any], query: str, **kwargs: Any):
        """Retrievalの処理開始時"""
        pass

    def on_retriever_error(self, error: BaseException, **kwargs: Any):
        """Retrievalのエラー発生時"""
        pass

    def on_retriever_end(self, documents: Sequence[Document], **kwargs: Any):
        """Retrievalの処理終了時"""
        pass

    def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs: Any):
        """エージェントに渡したToolの動作開始時"""
        pass

    def on_tool_error(self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any):
        """エージェントに渡したTool動作中のエラー発生時"""
        pass

    def on_tool_end(self, output: str, **kwargs: Any):
        """エージェントに渡したToolの動作終了時"""
        pass

    def on_agent_action(self, action: AgentAction, **kwargs: Any):
        """エージェントの特定アクション開始時"""
        pass

    def on_agent_finish(self, finish: AgentFinish, **kwargs: Any):
        """エージェントの特定アクション終了時"""
        pass

from loguru import logger

from langchain.callbacks import FileCallbackHandler
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain import LLMChain

logfile = "output.log"

logger.add(logfile)
handler = FileCallbackHandler(logfile)

from langchain.prompts import (ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate,)
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

human_template = "{input}が上達するためのおすすめの方法やアドバイスを教えてください。"

prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(system_template),
    HumanMessagePromptTemplate.from_template(human_template),
])

llm = ChatOpenAI(
    model_name="gpt-4o-mini",
    temperature=0.5,
    streaming=True,
    callbacks=[CustomCallbackHandler(), StreamingStdOutCallbackHandler()],
    )

chain = LLMChain(prompt=prompt, llm=llm)
result = chain.run(input="けん玉")
logger.info(result)
print(result)