# -*- coding: utf-8 -*-
"""Chapter5:【提出課題】LLM as a Judgeによる評価

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14mTHjL51r4xKv5K0f6aYnpIPu79PEU0p

# Lesson22: 生成AIの評価と改善
# Chapter5:【提出課題】LLM as a Judgeによる評価

事前準備を行った上で、提出課題に取り組みましょう。

**【提出方法】**  
Slackでメンターをメンションの上、当シート右上の「共有」からリンクをコピーし、提出してください。

## 事前準備

### 【OpenAI APIキーの設定】

OpenAI APIキーの設定
"""

import os
from google.colab import userdata

os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY")

"""ライブラリのインストール"""

!pip install langchain==0.3.0 openai==1.47.0 langchain-community==0.3.0 httpx==0.27.2

"""### 【データの用意】

サイドバーのファイルエリア上で「data」フォルダを作り、フォルダ内に以下3つのファイルをアップロードしましょう。  
※まずはGoogleドライブからダウンロードする必要があります。

**【ファイルが保存されているフォルダ】**  

「Lesson13: LangChainの主要モジュール4【Retrieval（RAG）】」フォルダ  
└「演習問題/提出課題」フォルダ  
└└「提出課題用データ」フォルダ

**【ファイル】**  
*   healthX_instructions.pdf（サービス詳細）
*   healthX_制作及び保守業務仕様書.pdf
*   20241207_MTG議事録_healthXのマーケティング施策について.pdf

## 提出課題

### 【問題文】

「Lesson13: Retrieval（RAG）」の演習問題5で扱ったRAGシステムの回答結果に対して、

 以下の条件でLLM as a Judgeによる評価を行ってください。

**【条件】**
*   「スコアによる評価」と「回答比較による評価」のそれぞれで評価を行ってください。
*   「回答比較による評価」では、異なる5つの回答に対して評価を行ってください。
*   評価用のプロンプトには6つの評価観点を含めてください。

### 【回答取得用のコード】
"""

!pip install pymupdf==1.24.11 chromadb==0.5.11 tiktoken==0.8.0

from langchain_community.document_loaders import PyMuPDFLoader
import os

folder_name = "data"
files = os.listdir(folder_name)

docs = []
for file in files:
    if not file.endswith(".pdf"):
        continue
    loader = PyMuPDFLoader(f"{folder_name}/{file}")
    pages = loader.load()
    docs.extend(pages)

from langchain.text_splitter import CharacterTextSplitter

text_splitter = CharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=30,
    separator="\n",
)

splitted_pages = text_splitter.split_documents(docs)

from langchain.embeddings.openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()

from langchain.vectorstores import Chroma

if os.path.isdir(".healthX_db"):
    db = Chroma(persist_directory=".healthX_db", embedding_function=embeddings)
else:
    db = Chroma.from_documents(splitted_pages, embedding=embeddings, persist_directory=".healthX_db")

retriever = db.as_retriever()

from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)
chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever
)

query = "HealthXの無料プランについて教えてください。"

result = chain.run(query)
print(result)

"""### 【スコアによる評価】"""

# RAGシステムにおいてLLMに点数評価をしてもらうためのプロンプト
# {question}と{answer}、{context}が、
# それぞれユーザー入力値とそれに対しての回答、外部参照先のデータソースで置き換えられる
prompt_template = """
以下に記載の「質問」に対しての「回答」について、
「ドキュメント」情報を参照した上で「評価観点」をもとに
理由と併せて「0〜100」で点数を付けてください。
誤りや不正確な情報が含まれている場合は、具体的に指摘してください。

【質問】
{question}

【回答】
{answer}

【評価観点】
1. 回答が提供されたドキュメントの情報に基づいているか？
2. ドキュメントと矛盾する内容が回答に含まれていないか？
3. 回答がドキュメントの文脈を正確に反映しているか？
4. 回答が質問に対して十分に網羅的であるか？
5. 回答が論理的で一貫性があるか？
6. 回答に根拠や具体例が示されているか？

【ドキュメント】
{context}
"""
from langchain.prompts import PromptTemplate

# このプロンプトのオブジェクトを後ほどChainに渡すことで、
# 「input_variables」に指定した「question」と「context」が、
# それぞれ入力内容と外部参照先のデータソースに置き換えられる
prompt = PromptTemplate(
    template=prompt_template,
    input_variables=["question", "context"],
    partial_variables={"answer": result}
)

# 「prompt」のキーに対してプロンプトのオブジェクトを指定することで、
# RetrievalQAにおいて独自のプロンプトを設定することができる
chain_type_kwargs = {"prompt": prompt}

# RetrievalQAのChainを作成し、入力内容を渡してChainを実行し、LLMによる評価結果を取得
# 「llm」と「retriever」引数には前のChapterで定義済みのものを指定し、
# 「chain_type_kwargs」引数にはプロンプトのオブジェクトを渡している
chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    chain_type_kwargs=chain_type_kwargs
)
evaluation_result = chain.run(query)
print("\n＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝")
print("＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝　スコアによる評価結果　＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝")
print("＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n")
print(evaluation_result)

"""### 【回答比較による評価】"""

prompt_template = """
以下に質問と5つの回答があります。
それぞれの回答を以下の評価観点を元に評価し、どちらがより優れているかを選択してください。
また、より優れた回答であると判断した理由を説明してください。
さらに、選択された回答内容に誤りや不正確な情報が含まれている場合は、具体的に指摘してください。

【質問】
{question}

【回答1】
{answer1}

【回答2】
{answer2}

【回答3】
{answer3}

【回答4】
{answer4}

【回答5】
{answer5}

【評価観点】
1. 回答が提供されたドキュメントの情報に基づいているか？
2. ドキュメントと矛盾する内容が回答に含まれていないか？
3. 回答がドキュメントの文脈を正確に反映しているか？
4. 回答が質問に対して十分に網羅的であるか？
5. 回答が論理的で一貫性があるか？
6. 回答に根拠や具体例が示されているか？

【ドキュメント】
{context}
"""

answer1 = """
「HealthX」では、ユーザーが健康維持に対して持続的な興味を持ち、日々の健康活動を積極的に行えるような仕掛けが用意されていますが、具体的な内容についてはわかりません。
"""
answer2 = """
カスタマイズされたアドバイス**: AIを活用して、ユーザーごとに個別のフィードバックをリアルタイムで提供します。
これにより、ユーザーは自分の健康状態を把握し、改善策を講じることができます。
"""
answer3 = """
シンプルで直感的なユーザーインターフェース**: 操作が簡単で、誰でもすぐに使いこなせるように設計されています。
"""
answer4 = """
ゲーミフィケーションの要素**: ユーザーが健康目標を達成するたびにポイントを獲得し、そのポイントをバッジや特典と交換できる仕組みがあり、健康管理を楽しめるようにしています。
"""
answer5 = """
多様な問い合わせオプション**: 健康管理に関する疑問や技術的な問題について、さまざまなチャネルを通じてサポートを受けられる体制が整っています。
"""

prompt = PromptTemplate(
    template=prompt_template,
    input_variables=["question", "context"],
    partial_variables={"answer1": answer1, "answer2": answer2, "answer3": answer3, "answer4": answer4, "answer5": answer5}
)

chain_type_kwargs = {"prompt": prompt}

chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    chain_type_kwargs=chain_type_kwargs
)

evaluation_result = chain.run(query)

print("\n＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝")
print("＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝　回答比較による評価結果　＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝")
print("＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n")
print(evaluation_result)

















