# -*- coding: utf-8 -*-
"""Chapter4:【提出課題: 解答用】LLMが会話履歴を元に回答を生成してくれていることを確認してみよう

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WNkWWNvJGfLYp_mnzj08mp9oNHxH-npK

# Lesson8: LangChainの主要モジュール1【Model I/O】：Language models
# Chapter4:【提出課題: 解答用】LLMが会話履歴を元に回答を生成してくれていることを確認してみよう

事前準備を行った上で、提出課題に取り組みましょう。

**【提出方法】**  
Slackでメンターをメンションの上、当シート右上の「共有」からリンクをコピーし、提出してください。

## 事前準備

OpenAI APIキーの設定
"""

import os
from google.colab import userdata

os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY")

"""各種パッケージのインストール"""

!pip install langchain==0.3.0 openai==1.47.0 langchain-community==0.3.0 langchain-openai==0.2.2 httpx==0.27.2

"""## 提出課題
Chat Completions APIが会話履歴を元に回答を生成してくれていることを確認してみましょう。

### 【ヒント】

「私の名前は〇〇です」の〇〇に自分の名前を入れたテキストをHumanMessageクラスに渡した上で、AIMessageクラスを使って擬似的に回答を用意し、それに対して再度HumanMessageクラスで「私の名前が分かりますか？」と質問すれば、AIが会話履歴を元に回答を生成してくれていることを確認できます。

※「AIMessage」はroleがassistantのメッセージを扱うクラスであり、「SystemMessage」「HumanMessage」と同じくlangchainパッケージのschemaモジュールから読み込めます。

### 【解答】
"""

from langchain_openai import ChatOpenAI

from langchain.schema import SystemMessage, HumanMessage, AIMessage

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

messages = [

    SystemMessage(content="You are a helpful assistant."),

    HumanMessage(content="私の名前は大川雄一です"),

    AIMessage(content="はじめまして。大川雄一さん。宜しくお願いいたします。"),

    HumanMessage(content="私の名前が分かりますか？"),

]

result = llm(messages)

print(result.content)