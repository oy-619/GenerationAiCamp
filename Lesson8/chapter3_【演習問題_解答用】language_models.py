# -*- coding: utf-8 -*-
"""Chapter3: 【演習問題: 解答用】Language models

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aQ2zAyBt5bt52X2dWamKiCNhBNCNs1hW

# Lesson8: LangChainの主要モジュール1【Model I/O】：Language models
# Chapter3:【演習問題: 解答用】Language models

事前準備を行った上で、3つの演習問題に取り組みましょう。

各問題の「回答例/正解」と「解説」はデフォルトで非表示としていますが、  
非表示セルをクリックすれば確認できます。

まずは「回答例/正解」と「解説」を見ずにトライしてみましょう。
"""



"""## 事前準備

OpenAI APIキーの設定
"""

import os
from google.colab import userdata

os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY")

"""各種パッケージのインストール"""

!pip install langchain==0.3.0 openai==1.47.0 langchain-community==0.3.0 langchain-openai==0.2.2 httpx==0.27.2

"""## 演習問題

### 【問題1】
roleがsystemのメッセージを「あなたは優秀なファッションスタイリストです。」、roleがuserのメッセージを「フォーマルな場にふさわしいコーディネートを教えてください。」とし、Chat Completions APIから回答を生成してください。
"""

from langchain_openai import ChatOpenAI

from langchain.schema import SystemMessage, HumanMessage

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

messages = [

    SystemMessage(content="あなたは優秀なファッションスタイリストです。"),

    HumanMessage(content="フォーマルな場にふさわしいコーディネートを教えてください。"),

]

result = llm(messages)

print(result.content)

"""#### 【解答例】"""

from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

messages = [
    SystemMessage(content="あなたは優秀なファッションスタイリストです。"),
    HumanMessage(content="フォーマルな場にふさわしいコーディネートを教えてください。"),
]

result = llm(messages)
print(result.content)

"""#### 【解説】

Chat Completions APIを使う際、roleがsystemのメッセージは「SystemMessage」クラスで、roleがuserのメッセージは「HumanMessage」クラスで作ります。  

SystemMessageクラスのcontentパラメータに「あなたは優秀なファッションスタイリストです。」、HumanMessageクラスのcontentパラメータに「フォーマルな場にふさわしいコーディネートを教えてください。」を指定してチャットリストを作り、Chat Completions APIに渡せば回答を生成できます。

### 【問題2】
当Lessonで解説した以下コードを実行し、Chat Completions APIの生成結果が格納されている変数「result」の中身を表示して、プロンプトの消費トークン数を答えてください。
"""

from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content="日本の首都を教えてください。"),
]

result = llm(messages)
print(result)
token_usage = result.response_metadata["token_usage"]
print(f"プロンプトの消費トークン数：{token_usage['prompt_tokens']}")

"""#### 【解答】
プロンプトのトークン数：26

#### 【正解】

プロンプトのトークン数：26

#### 【解説】

以下は、Chat Completions APIの生成結果（変数「result」の中身）の例です。  
（content、completion_tokens、total_tokens、idは人によって異なります）

---

content='日本の首都は東京です。東京は日本の政治、経済、文化の中心地であり、多くの重要な機関や企業が集まっています。'  
additional_kwargs={}  
response_metadata=  
　 {  
　　　'token_usage':  
　　　　{  
　　　　　'completion_tokens': 37,   
　　　　　'prompt_tokens': 26,   
　　　　　'total_tokens': 63,   
　　　　　'completion_tokens_details': {'reasoning_tokens': 0},  
　　　　　'prompt_tokens_details': {'cached_tokens': 0}  
　　　　},   
　　　'model_name': 'gpt-4o-mini',   
　　　'system_fingerprint': None,   
　　　'finish_reason': 'stop',   
　　　'logprobs': None  
　}  
id='run-76a843db-a340-4fc7-a4f7-58de4dff4c64-0'

---

「response_metadata」の中の、「token_usage」の中に使用トークン数に関わるデータが入っています。

プロンプトの消費トークン数は、「prompt_tokens」に入っています。

ちなみに出力の消費トークン数は「completion_tokens」、入出力の合計トークン数は「total_tokens」に入っています。

### 【問題3】
入力の消費トークン数を「26」、出力の消費トークン数を「37」とした場合、【問題2】のコードを一回実行するたびに料金がいくらかかるかを米ドルで計算しましょう。  
※「gpt-4o-mini」を指定した際に使われるモデルは「gpt-4o-mini-2024-07-18」とします。

### 【ヒント】

*   「gpt-4o-mini」を指定してモデルを呼び出すと、該当モデルにおける最新日付けのモデルが呼び出されます。執筆時点（2024年12月時点）で、「gpt-4o-mini」の最新モデルは「gpt-4o-mini-2024-07-18」です。  
※実際の最新モデルは、検索エンジンで「gpt-4o-mini latest」などと検索すれば調べられます。
*   「gpt-4o-mini-2024-07-18」の「Input（入力）」と「Output（出力）」の料金をもとに算出します。  
※InputとOutputのそれぞれで1トークン当たりの料金は異なります。

### 【コード】
"""

from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content="日本の首都を教えてください。"),
]

result = llm(messages)
print(result)

"""#### 【解答】
料金：0.0000261

#### 【正解】

0.0000261（米ドル）

#### 【解説】

「gpt-4o-mini-2024-07-18 price」と検索すると、OpenAIの以下ページがヒットします。  
https://openai.com/api/pricing/  

「gpt-4o-mini-2024-07-18」の料金を確認すると、入力（Input）については「\$0.150 / 1M tokens」、出力（Output）については「$0.600 / 1M tokens」であることが分かります。ちなみに、「1M」は「100万」を表しています。

入力の消費トークン数を「26」、出力の消費トークン数を「37」とした場合、消費トークン数の合計は以下となります。

・入力の消費トークン数：26 * 0.150 / 1,000,000 = 0.0000039（米ドル）  
・出力の消費トークン数：37 * 0.600 / 1,000,000 = 0.0000222（米ドル）  
・合計の消費トークン数：0.0000039 + 0.0000222 = 0.0000261（米ドル）
"""