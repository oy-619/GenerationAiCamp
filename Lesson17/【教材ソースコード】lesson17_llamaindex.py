# -*- coding: utf-8 -*-
"""【教材ソースコード】Lesson17: LlamaIndex

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XFFN6UBlzJ0j3Aci4cOCjfv9z2oKGRl5

# 【教材ソースコード】Lesson17: LlamaIndex

## 事前準備

OpenAI APIキーの設定
"""

import os
from google.colab import userdata

os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY")

"""ライブラリのインストール"""

!pip install langchain==0.3.22 openai==1.70.0 langchain-community==0.3.20 httpx==0.28.1

"""## 教材サンプルコード

### Chapter2: LlamaIndexの基本

---

#### 事前準備

パッケージのインストール
"""

!pip install llama-index==0.12.7

"""Googleドライブのマウント"""

from google.colab import drive
drive.mount('/content/drive')

"""フォルダパスの設定"""

source_folder = "/content/drive/MyDrive/Lesson17_data"

"""#### RAGシステムの開発

ドキュメントの読み込み
"""

from llama_index.core import SimpleDirectoryReader

documents = SimpleDirectoryReader(source_folder).load_data()

"""要素数の確認"""

len(documents)

"""インデックス化の処理"""

from llama_index.core import GPTVectorStoreIndex

index = GPTVectorStoreIndex.from_documents(documents)

"""クエリエンジンの作成"""

query_engine = index.as_query_engine()

"""ユーザー入力値を与えて回答を取得"""

result = query_engine.query("LangChainの開発経験を活かせる求人を教えて。日本語で回答して。")

"""回答の取り出し"""

result.response

"""参照元ファイルパスの取得"""

duplicate_check = []
for node in result.source_nodes:
    source_file_path = node.metadata["file_path"]
    if source_file_path in duplicate_check:
        continue
    duplicate_check.append(source_file_path)
    print(source_file_path)

"""データベースをディスク上に保存"""

index.storage_context.persist()

"""ディスク上に保存したデータベースの読み込み"""

from llama_index.core import StorageContext, load_index_from_storage

storage_context = StorageContext.from_defaults(persist_dir="storage")
index = load_index_from_storage(storage_context)

"""### Chapter3: 各種設定のカスタマイズ方法

---

#### モデルのカスタマイズ

モデル設定用のパッケージをインストール
"""

!pip install llama-index-llms-langchain==0.5.0

from llama_index.core import Settings
from langchain.chat_models import ChatOpenAI

Settings.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.5)

"""#### 埋め込みモデルのカスタマイズ"""

from llama_index.core import Settings
from llama_index.embeddings.openai import OpenAIEmbedding

Settings.embed_model = OpenAIEmbedding(
    model="text-embedding-3-small"
)

"""#### チャンク分割のカスタマイズ"""

from llama_index.core import Settings
from llama_index.core.node_parser import SentenceSplitter
import tiktoken

Settings.text_splitter = SentenceSplitter(
    chunk_size=1000,
    chunk_overlap=50
)

"""#### 抽出する関連情報の最大値のカスタマイズ"""

query_engine = index.as_query_engine(
    similarity_top_k=5
)

"""### Chapter4: LlamaHubの概要と基本的な使い方

---

指定したWebページからのデータ読み込み
"""

from llama_index.core import download_loader

BeautifulSoupWebReader = download_loader("BeautifulSoupWebReader")
loader = BeautifulSoupWebReader()
documents = loader.load_data(urls=[
    "https://generative-ai.web-camp.io/courses/basic/",
    "https://generative-ai.web-camp.io/courses/marketing/",
    "https://generative-ai.web-camp.io/courses/sales/",
    "https://generative-ai.web-camp.io/courses/engineer/"
])

"""データベースの作成"""

from llama_index.core import GPTVectorStoreIndex

index = GPTVectorStoreIndex.from_documents(documents)

"""クエリエンジンの作成"""

query_engine = index.as_query_engine()

"""LLMからの回答取得（1回目）"""

result = query_engine.query("プロンプトエンジニアリングコースの「営業コース」は、どんな人におすすめですか？日本語で答えて")
result.response

"""LLMからの回答取得（2回目）"""

result = query_engine.query("生成AIエンジニアコースの特徴を日本語で答えて")
result.response